{
 "metadata": {
  "name": "",
  "signature": "sha256:79468d88db4ab6f65d0092ee447d71d27f3fa3d6f9003730082398cbf89474a8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Guest Lecture: Artificial Neural Networks \n",
      " - Mike Tamir\n",
      "    \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Imports\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from IPython.display import YouTubeVideo\n",
      "%pylab inline\n",
      "from mpl_toolkits.mplot3d import Axes3D"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# What are Artificial Neural Networks?\n",
      "### Conceptual Introduction\n",
      "\n",
      "Artificial Neural Networks (ANNs) are a staple of machine learning classifiers.  The inspiration for the classifiers is loosely based on the way networks of \"neurons\" work in the brain.  \n",
      "   - (Biological) neurons are connected by nerve fibers to one another\n",
      "   - When a neuron is triggered, it fires a chemical signal across the Synaptic Gap\n",
      "   - Signals received from other neurons networked to a given cell (stochastically) determine if the given cell will fire, in turn triggering other cells in the network."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![From EngineersGarage](http://www.engineersgarage.com/sites/default/files/imagecache/Original/wysiwyg_imageupload/1/Neural-Networks2.jpg)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similarly, ANNs form a network of artificial \"neurons\" (nodes).  The network of artificial neurons are broken up into three classes:\n",
      " - An **input layer**, into which the initial training data is fed.\n",
      " - One or more **hidden layers**.\n",
      "     - Machine learning using ANNs with multiple hidden layers is referred to as **\"deep learning\"**.\n",
      " - An **output layer**, which produces the final classification results.\n",
      "     - The output layer can consist of a *single node* for binary classification,\n",
      "     - Or it may have multiple nodes for multi-class classification.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![From EngineersGarage](http://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/300px-Colored_neural_network.svg.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will get back to how to interpret these arrows below..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## A Brief History of Artificial Neural Networks\n",
      "\n",
      "### Single layer (linear) perceptron networks:\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def perceptronLogic(training_set, learning_rate, threshold, initial_weights = [0,0,0], divergence = 100000, printing = True):\n",
      "    \n",
      "    '''\n",
      "    This classifier executes a single layer (linear) perceptron algorithm for Boolean Logical operators  \n",
      "    (xor, or, and, etc...).                                                                              \n",
      "                                                                                                         \n",
      "    Output is the final weights for the perceptron single layer, or a \"failure to converge\" message.     \n",
      "                                                                                                         \n",
      "    training_set - is the set of data to train the model, and comes in the from of an array of objects ((x_0, x_1, x_2), y) where x_0 is the bias, x_1 and x_2 are the  inputs, and y is the Boolean  output.\n",
      "    initial_weigths - give the weight initialization default initial_weights = [0,0,0]                   \n",
      "    learning_rate -  is the \\alpha value                                                                 \n",
      "    threshold  - is the threshold value above which  the x and weights dot product must exceed           \n",
      "    divergence - if iterations exceed divergence number the \"failure to converge\" error results          \n",
      "    printing = True - turns on printing of the weight values with each iteration                         \n",
      "    '''\n",
      "    \n",
      "    iteration = 0 \n",
      "    while True:\n",
      "        iteration += 1\n",
      "        if printing == True:\n",
      "            print('-' * 60)\n",
      "        error_count = 0\n",
      "        for input_vector, desired_output in training_set:\n",
      "            if printing == True:\n",
      "                print \"Weights vector =\" + str(weights)\n",
      "            result = np.dot(input_vector, weights) > threshold\n",
      "            error = desired_output - result\n",
      "            if printing == True:\n",
      "                print \"error = \" + str(error)\n",
      "            if error != 0:\n",
      "                error_count += 1\n",
      "                for index, value in enumerate(input_vector):\n",
      "                    weights[index] += learning_rate * error * value\n",
      "            if printing == True:\n",
      "                print \"iteration number \" + str(iteration)\n",
      "            \n",
      "        if iteration >= divergence:\n",
      "            print \"WARNING: Failure to converge after \" + str(divergence) + \" iterations\"\n",
      "            break #problem?\n",
      "        if error_count == 0:\n",
      "            print \"error count converged to 0\"\n",
      "            print \"Final weights vector =\" + str(weights)\n",
      "            break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now lets check out the single layer perceptron works on a couple of Boolian operators:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "AND:   \n",
      "<table>\n",
      "    <tr>\n",
      "        <th>$x_1$</th><th>$x_2$</th><th>$ x_1 \\wedge x_2 $</th>\n",
      "    </tr>\n",
      "    <tr><td>1</td><td>1</td><td>1</td></tr>\n",
      "    <tr><td>1</td><td>0</td><td>0</td></tr>\n",
      "    <tr><td>0</td><td>1</td><td>0</td></tr>\n",
      "    <tr><td>0</td><td>0</td><td>0</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AND = [((1, 1, 1), 1),\n",
      "       ((1, 1, 0), 0), \n",
      "       ((1, 0, 1), 0),  \n",
      "       ((1, 0, 0), 0)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OR:\n",
      "<table>\n",
      "    <tr>\n",
      "        <th>$x_1$</th><th>$x_2$</th><th>$ x_1 \\vee x_2 $</th>\n",
      "    </tr>\n",
      "    <tr><td>1</td><td>1</td><td>1</td></tr>\n",
      "    <tr><td>1</td><td>0</td><td>1</td></tr>\n",
      "    <tr><td>0</td><td>1</td><td>1</td></tr>\n",
      "    <tr><td>0</td><td>0</td><td>0</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "OR =  [((1, 1, 1), 1),\n",
      "       ((1, 1, 0), 1), \n",
      "       ((1, 0, 1), 1),  \n",
      "       ((1, 0, 0), 0)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NAND:\n",
      "<table>\n",
      "    <tr>\n",
      "        <th>$x_1$</th><th>$x_2$</th><th>$ \\neg (x_1 \\wedge x_2) $</th>\n",
      "    </tr>\n",
      "    <tr><td>1</td><td>1</td><td>0</td></tr>\n",
      "    <tr><td>1</td><td>0</td><td>1</td></tr>\n",
      "    <tr><td>0</td><td>1</td><td>1</td></tr>\n",
      "    <tr><td>0</td><td>0</td><td>1</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NAND = [((1, 1, 1), 0), \n",
      "        ((1, 1, 0), 1), \n",
      "        ((1, 0, 1), 1), \n",
      "        ((1, 0, 0), 1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now lets check out how the perceptron algorithm works for some of these training sets:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#training_set = AND\n",
      "#training_set = OR\n",
      "training_set = NAND\n",
      "threshold = 0.5\n",
      "learning_rate = 0.1\n",
      "weights = [0, 0, 0]\n",
      "\n",
      "perceptronLogic(training_set = training_set, \n",
      "                learning_rate = learning_rate, \n",
      "                threshold = threshold, \n",
      "                initial_weights = [0,0,0], \n",
      "                divergence = 10000, \n",
      "                printing = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## XOR Problem\n",
      "Perceptron's will find a solution for a given set of training data, _if there is a solution_.  Unfortunately, in cases of non-linearly separable  data, a solution does not always exist.  \n",
      "\n",
      "Take for example the XOR data set:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "XOR: \n",
      "<table>\n",
      "    <tr>\n",
      "        <th>$x_1$</th><th>$x_2$</th><th>$ x_1 \\oplus x_2 $</th>\n",
      "    </tr>\n",
      "    <tr><td>1</td><td>1</td><td>0</td></tr>\n",
      "    <tr><td>1</td><td>0</td><td>1</td></tr>\n",
      "    <tr><td>0</td><td>1</td><td>1</td></tr>\n",
      "    <tr><td>0</td><td>0</td><td>0</td></tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "XOR = [((1, 1, 1), 0), \n",
      "       ((1, 1, 0), 1),\n",
      "       ((1, 0, 1), 1), \n",
      "       ((1, 0, 0), 0)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training_set = XOR\n",
      "threshold = 0.5\n",
      "learning_rate = 0.1\n",
      "weights = [0, 0, 0]\n",
      "\n",
      "perceptronLogic(training_set = training_set, \n",
      "                learning_rate = learning_rate, \n",
      "                threshold = threshold, \n",
      "                initial_weights = [0,0,0], \n",
      "                divergence = 100000, \n",
      "                printing = False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot it to take a look\n",
      "X = array([[0, 1], [1, 0], [0, 0], [1, 1]])\n",
      "Y = array([1, 1, 0, 0])\n",
      "N = Y.shape[0]\n",
      "\n",
      "scatter(X[:, 0], X[:, 1], c=Y, cmap=cm.rainbow_r, s=100)\n",
      "r = setp(gca(), xticks=(), yticks=())"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "align_type": "Left",
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because the data set is not linearly separable, our perceptron model cannot possibly converge to a solution."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Lets return to the ANN diagram:\n",
      "\n",
      "![From EngineersGarage](http://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/300px-Colored_neural_network.svg.png)\n",
      "## A little math...\n",
      "\n",
      "Each set of arrows between non-input layers of the ANN we learn a \"weight matrix\"\n",
      "\n",
      "## $$ W := [W]_{ji} $$\n",
      "\n",
      "Where each $[W]_{ji} $ entry defines the contribution of the  $ i^{th}$ neuron in the previous layer to the $j^{th}$ neuron on the next layer. \n",
      " - (Each $[W]_{ji} $ represents an \"arrow\" in other words.) \n",
      "\n",
      "Explicitly, if $\\overrightarrow{x^{(k-1)}} $ is the vector of outputs form the last  $ {(k-1)}^{th}$ layer, then the $i$ neurons on the  $ k^{th}$ layer are fed the following vector:\n",
      "\n",
      "## $$ \\overrightarrow{z^{(k)}} = W\\overrightarrow{x^{(k-1)}} $$\n",
      "\n",
      "\n",
      "the $ \\overrightarrow{z^{(k)}}$ vector is then transformed with an activation function\n",
      "\n",
      "## $$ f(\\overrightarrow{z^{(k)}}) = \\overrightarrow{x^{(k)}} $$ ##\n",
      "\n",
      "which defines how the \"triggers\" from the previous layer neurons translate into a signal $\\overrightarrow{x^{(k)}}$ that is sent from the current layer.  \n",
      " - (In other words, each node represents an \"activation function\" $ f(\\overrightarrow{z^{(k)}})$ describing how the neuron reacts to inputs from the previous layer.)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## So why do perceptrons fail to converge?\n",
      "\n",
      "The answer is that they were not using a good enough activation function.\n",
      "\n",
      "In order to seperate non-linearly seperable data, we need to add an element of non-linear transfomrations, likessigmod functions of the form:\n",
      "\n",
      " - ### $ f(\\overrightarrow{z_{(k)}}) = \\tanh(z_{(k)}) $ ###\n",
      " - ### $ f(\\overrightarrow{z_{(k)}}) = \\frac{1}{1+\\exp(-z_{(k)})} $ ###\n",
      "\n",
      "The second one you may recognize as the \"logistic function\"."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Plot of some activation functions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_afun(x, y, sp_idx, label=None):\n",
      "    \"\"\"Plot activation function.\"\"\"\n",
      "    ax = subplot(3, 3, sp_idx)\n",
      "    if label is not None: title(label)\n",
      "    setp(ax, xlim=(min(x), max(x)), ylim=(min(y)-0.5, max(y)+0.5))\n",
      "    plot(x, y)\n",
      "\n",
      "def logistic(z): \n",
      "    return 1.0/(1+exp(-z))    \n",
      "    \n",
      "figure(figsize=(18, 14))\n",
      "x = linspace(-5, 5, 100)\n",
      "\n",
      "plot_afun(x, x, 1, label=\"Linear\")\n",
      "plot_afun(x, numpy.max((sign(x), zeros_like(x)), axis=0), 2, label=\"Step Function\")\n",
      "plot_afun(x, numpy.max((x/3, zeros_like(x)), axis=0), 3, label=\"Rectified Linear\")\n",
      "plot_afun(x, np.piecewise(x, [x < 0, (x < 3) & (x >= 0),x >= 3], [0, lambda x: x/3.0, 1]), 4, label=\"Semi-Linear\")\n",
      "plot_afun(x, logistic(x), 5, label=\"Logistic Function\")\n",
      "plot_afun(x, tanh(x), 6, label=\"tanh\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Hidden layers as automated Feature Engeneering...\n",
      "\n",
      "One way to think about what is going on with ANNs is that each hidden layer is an exercise in figuring out the best way to Feature Engeneer the the input data in an automated way.\n",
      "\n",
      "- The $W$ matrix represents a round of \"rotation\" and \"linear streaching\" (and possible projections and translations when we include \"bias terms\").\n",
      "- Then at the neurons, the features can be *non-linearly* transformed by the activation functions.\n",
      "- With each hidden layer we are adding another round of linear (rotation + streaching + possible projections and translations) and then non-linear transformations:\n",
      "![](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/img/spiral.1-2.2-2-2-2-2-2.gif)\n",
      "\n",
      "   + gif courtsy of the excelent blog entry http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/\n",
      "\n",
      "\n",
      "## Lets see this working in action:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print YouTubeVideo(\"MkLJ-9MubKQ\").src\n",
      "YouTubeVideo(\"MkLJ-9MubKQ\")"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "align_type": "Left",
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Neural Network Learning\n",
      "\n",
      "### Which parameters must be learnt for a Neural network?\n",
      "\n",
      "Recall, for each of the non-input layers of a neural net, we must ostensibly learn each of the $W_{ji}$ matrix of weights, as well as the parameters associated with the activation functions at each node. This means that even with a small number of layers, the number of parameters that need to be learnt blows up very quickly\n",
      "\n",
      "### Example:\n",
      "For an ANN with 1 hidden layer, with just 3 nodes at each layer, one must learn:\n",
      "   - $3\\times3$ parameters for the first weight matrix,\n",
      "   - $3\\times3$ paameters for the second weight matrix, and\n",
      "   - For a total of **81** different parameters to be learnt.\n",
      "    \n",
      "Since grid search is exponential in the number of parmeters that need to be learnt, even for the simplist of networks, it is not practical to optimize with brute force learning.\n",
      "\n",
      "\n",
      "Instead, a technique known as _Backwards propigation_ or \"_Backprop_\" is used to efficiently learn the parameters of the weight matricies."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# What is Backprop?\n",
      "- Backwards propagation is an algorithm for calculating the \"gradient error function\" of an ANNs weights $W$\n",
      "- By calculating the gradient the algorithm updates $W$ until a minimum in the Error function is reached.\n",
      "- The gradient decent can be executed in\n",
      "  - Batch GD (using all the data, update and then run again),\n",
      "  - Semi-Batch GD (using small batches of the data at a time, updating, and running again), or\n",
      "  - Stochastic GD (updating with each new data point)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Backprop: Algorithm Details\n",
      "Backward propagation learning has two phases: propagation and weight update.\n",
      "\n",
      "1. Propagation Phase\n",
      "    1. To begin, the training data is \"Forward Propagated\" through the ANN to determine the activation values  ( $\\overrightarrow{z^{(k)}}$ ) fed into each layer and resulting from the final output.\n",
      "    2. For the \"Backward Propagation\" direction, a series of $\\delta_i$ values used to update the weight values $W_ij$ are calculated by comparing the output of the final layer to the target value of the training data and the dependency of that output on the activations of previous layers. \n",
      "\n",
      "2. Weight update Phase\n",
      "    1. Following the Propagation Phase, the weight values fanning into each node are updated. \n",
      "    2. The new weight is calculated by taking the product of the output delta and input activation to get the gradient of the weight.\n",
      "    3. The updated weight is calculated by subtracting a percentage ($ \\alpha $ of this value from the original weight.\n",
      "        4. $\\alpha $ is referred to as the **learning rate** and influences the speed of learning process. \n",
      "        5. The lower the $\\alpha $, the more accurate (but slow) the training is. \n",
      "\n",
      "Phases 1 and 2 are repeated until optimal Error performance on the training data is achieved."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Backprop lerning (The Math):\n",
      "\n",
      "## ForwardProp\n",
      "\n",
      "Recall, for each layer:\n",
      "\n",
      "### $$z^{(k)}_j = \\sum_i W_{ji} x^{(k-1)}_i$$ ###\n",
      "### $$x^{(k)}_j = f(z^{(k)}_j)$$ ###\n",
      "\n",
      "Error function (SSE)\n",
      "\n",
      "### $$E = \\frac{1}{2} \\sum_n \\left( \\overrightarrow{y_{(n)}} - \\overrightarrow{\\hat{y}_{(n)}} \\right)^2$$ ###\n",
      "\n",
      "where\n",
      " - $x^{(k)}_j$ is the $j^{th}$ output of the $k^{th}$ layer\n",
      " - $x^{(k-1)}_i$ is the $i^{th}$ output of the $(k-1)^{th}$ layer\n",
      " - $W_{ji}$ is the the element of the weight matrix from i to j\n",
      " - $z_{j}$ is activation value fed to the $j^{th}$ neuron\n",
      " - $f$ is the activation function, in the hidden layers\n",
      " - $\\overrightarrow{y_{(n)}}$ is the actual target output vector for the for the $n^{th}$ training data point\n",
      " - $\\overrightarrow{\\hat{y}_{(n)}}$ is the predicted target output from the $n^{th}$ training data point\n",
      " "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "align_type": "Left",
       "slide_type": "slide"
      }
     },
     "source": [
      "## Backprop\n",
      "In each layer (we will omit the sample index $n$)\n",
      "\n",
      "### $$\\Delta W_{ij} = - \\alpha  \\frac{\\partial E}{\\partial W_{ij}} = - \\alpha (\\delta_j x_i)$$\n",
      "\n",
      "where\n",
      "### $$\\delta_j = \\begin{cases}\\hat{y_j} - y_j & \\text{in the output layer}\\\\\\\\ f'(z_j) ({\\sum_{k>j} {\\delta_k W_{kj}}}) & \\text{otherwise}\\end{cases}.$$ "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Challenges with Backprop\n",
      "## Challenge 1: Slow learning due to elliptical error surface.\n",
      "   - This leads to a \"zigzag\" phenomenon as the algorithm searches for a minimum of the error surface:\n",
      "![elliptical](http://www.willamette.edu/~gorr/classes/cs449/figs/valley1.gif)\n",
      "\n",
      "\n",
      "\n",
      "   - The \"zigzag\" effect is like when someone riding a snowboard goes down a half-pipe. \n",
      "     + At the edge, the direction of steepest decent is not directly along the pipe, it is toward the min at the center of cross sections of the pipe (or ellipse).  \n",
      "     + By the time you get to the bottom, too much momentum is built up, and the snowboarder (algorithm) starts going back up and needs to turn around again.  \n",
      "     + This leads to slow learning.\n",
      "    \n",
      "    \n",
      "![half-pipe](http://newsimg.bbc.co.uk/media/images/41185000/gif/_41185544_halfpipe_416.gif)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Solutions to Challenge 1**\n",
      "1. Challenge 1 is generally solved by strategically modifying the learning rate. In general, if the error grows or we see oscillation, the learning rate must be turned down, but if the error is falling reliably (but slowly) the learning rate may need to be turned up. \n",
      "   1. **Momentum Methods** - These methods work to \"turn down the speed\" of the learning rate by paying attention to the \"speed\" of decent progress (breaking as you approach the bottom of the half pipe).\n",
      "     - These methods can be advanced to implement but can be very effective in speeding up learning.\n",
      "     - Momentum methods can typically be used _in combination_ with other techniques.\n",
      "     <br / >\n",
      "     <br / >\n",
      "   2. **Adaptive Learning** - These methods work to slow down based on the curvature of the error surface, looking at the gradient.\n",
      "     - Other techniques such as will focus on detecting oscillations (e.g. looking at directional flips in the gradient) to slow down the learning rate (e.g. RMSprop)\n",
      "   <br />\n",
      "   <br />\n",
      "2. **Prepare the Data** - A major cause of the zigzag effect is the elliptical shape of the error surface. For a circular error surface, the gradient will point to a true local minimum. Some simple tricks that can help make the error surface more symmetrical (and easier to find the bottom):\n",
      "   1. Running a PCA on the data can also help keep the round out the error surface by de-correlating the PC dimensions.\n",
      "   2. *Mean shift* the data so that it is centered around 0, and then *normalize* the data (e.g. divide by the SD).\n",
      "     - Note: Mean shifted data tends to work better with a $tanh()$ activation (over a logistic one) as the former is centered about 0."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Challenge 2: Local Minima\n",
      "  - The error surfaces being optimized in ANN gradient decent will not have a single global minimum. Because of this, the algorithm can frequently find only a local (but non-global) minima.\n",
      "\n",
      "![local minima](http://www.mathworks.com/matlabcentral/fileexchange/screenshots/7407/original.jpg)\n",
      "\n",
      "### This happens even in the simplest of cases, like our XOR error surface:\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot the error surface for XOR\n",
      "def logistic(z): \n",
      "    return 1.0/(1+exp(-z))\n",
      "\n",
      "def fprop(x1,x2,w1=0.1,w2=0.2,b1=0.1,w3=-0.2,w4=0.2,b2=-0.1,w5=-0.3,w6=-0.25,b3=0.2):\n",
      "    return logistic(b1+w1*logistic(b2+w3*x1+w4*x2)+w2*logistic(b3+w5*x1+w6*x2))\n",
      "\n",
      "i, j = 4, 5 # Weight indices\n",
      "fig = figure(figsize=(10, 8))\n",
      "W1, W2 = meshgrid(arange(-10, 10, 0.25), arange(-10, 10, 0.25))\n",
      "E = numpy.sum([(fprop(X[n, 0], X[n, 1], **{\"w%d\"%(i+1) : W1, \"w%d\"%(j+1) : W2})-Y[n])**2\n",
      "               for n in range(N)], axis=0)\n",
      "ax = fig.add_subplot(111, projection=\"3d\")\n",
      "surf = ax.plot_surface(W1, W2, E, rstride=1, cstride=1,\n",
      "                       cmap=cm.coolwarm, lw=0)\n",
      "setp(ax, xticks=(), yticks=(), zticks=(),\n",
      "     xlabel=\"$W_{11}$\", ylabel=\"$W_{12}$\", zlabel=\"Error surface\")\n",
      "matplotlib.rcParams.update({\"font.size\": 20})"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "align_type": "Left",
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Challenge 3: Over Fitting\n",
      "Because ANNs involve so many degrees of freedom in the learnt parameters, over fitting the training data is another common challenge.  Over-fitting can be avoided by a number of methods:\n",
      " - $L_1$ and $L_2$ **regularization** will drive down weight values $W_{ij}$ .\n",
      " - Regularization effects can also be achieved by **adding noise** to the training data.\n",
      " - **Early stoping** - by terminating the backprop cycle early overfitting can also be avoided\n",
      " - One risk of deep nets is that early layers can over fit and be re-compensated for in earlier layers.  The **Dropout Method** in which multiple versions of the network are trained with nodes removed and then the weight matrices are averaged together, will add more stability and prevent this phenomenon."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "align_type": "Left",
       "slide_type": "fragment"
      }
     },
     "source": [
      "# Initializing the weights $ W_{ij}$\n",
      "* Draw components of $W_{ij}$ iid (independent and identically distributed) from a Gaussian distribution with **small** standard deviation, e.g. 0.05.\n",
      "* Otherwise the symmetry of the system will not allow it to learn different weight values for the nodes\n",
      "* Initialization with 0 will prevent the gradient from flowing back to the lower layers:\n",
      "### $$\\frac{\\partial E}{\\partial x_i} = \\delta_j W_{ji}$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#generating random values for W_ij\n",
      "random.randn(10) * 0.05"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "align_type": "Left",
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Practice with the Theano Tutorial.\n",
      "The following is taken (with minor adaptations from [Theano project tutorial](http://nbviewer.ipython.org/github/craffel/theano-tutorial/blob/master/Theano%20Tutorial.ipynb).  \n",
      "\n",
      "In order to run through this tutorial, you will have to install Theano on your machine.  The following pip install will work for MAC users:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Installing theano on MAC:\n",
      "#!pip install Theano\n",
      "\n",
      "### If you use Anaconda this may be needed:  \n",
      "#!export DYLD_FALLBACK_LIBRARY_PATH=$DYLD_FALLBACK_LIBRARY_PATH:/Users/[YOUR_USER_NAME]]/anaconda/lib\n",
      "\n",
      "### Check with this command:\n",
      "#!echo $DYLD_FALLBACK_LIBRARY_PATH\n",
      "\n",
      "### Or you might try:\n",
      "#!pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
      "\n",
      "\n",
      "\n",
      "import theano\n",
      "# By convention, the tensor submodule is loaded as T\n",
      "import theano.tensor as T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Layer class \n",
      "\n",
      "We'll be defining our multilayer perceptron as a series of \"layers\", each applied successively to the input to produce the network output.  Each layer is defined as a class, which stores a weight matrix and a bias vector and includes a function for computing the layer's output.  \n",
      "\n",
      "### (A differnece in Theano)\n",
      "Note that if we weren't using Theano, we might expect the `output` method to take in a vector and return the layer's activation in response to this input.  However, with Theano, the `output` function is instead meant to be used to _create_ (using `theano.function`) a function which can take in a vector and return the layer's activation.  So, if you were to pass, say, a `np.ndarray` to the `Layer` class's `output` function, you'd get an error.  Instead, we'll construct a function for actually computing the `Layer`'s activation outside of the class itself.\n",
      "\n",
      "(For Theano basics details see the tutorial link posted above.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Layer(object):\n",
      "    def __init__(self, W_init, b_init, activation):\n",
      "        '''\n",
      "        A layer of a neural network, computes s(Wx + b) where s is a nonlinearity and x is the input vector.\n",
      "\n",
      "        :parameters:\n",
      "            - W_init : np.ndarray, shape=(n_output, n_input)\n",
      "                Values to initialize the weight matrix to.\n",
      "            - b_init : np.ndarray, shape=(n_output,)\n",
      "                Values to initialize the bias vector\n",
      "            - activation : theano.tensor.elemwise.Elemwise\n",
      "                Activation function for layer output\n",
      "        '''\n",
      "        # Retrieve the input and output dimensionality based on W's initialization\n",
      "        n_output, n_input = W_init.shape\n",
      "        # Make sure b is n_output in size\n",
      "        assert b_init.shape == (n_output,)\n",
      "        # All parameters should be shared variables.\n",
      "        # They're used in this class to compute the layer output,\n",
      "        # but are updated elsewhere when optimizing the network parameters.\n",
      "        # Note that we are explicitly requiring that W_init has the theano.config.floatX dtype\n",
      "        self.W = theano.shared(value=W_init.astype(theano.config.floatX),\n",
      "                               # The name parameter is solely for printing purporses\n",
      "                               name='W',\n",
      "                               # Setting borrow=True allows Theano to use user memory for this object.\n",
      "                               # It can make code slightly faster by avoiding a deep copy on construction.\n",
      "                               # For more details, see\n",
      "                               # http://deeplearning.net/software/theano/tutorial/aliasing.html\n",
      "                               borrow=True)\n",
      "        # We can force our bias vector b to be a column vector using numpy's reshape method.\n",
      "        # When b is a column vector, we can pass a matrix-shaped input to the layer\n",
      "        # and get a matrix-shaped output, thanks to broadcasting (described below)\n",
      "        self.b = theano.shared(value=b_init.reshape(-1, 1).astype(theano.config.floatX),\n",
      "                               name='b',\n",
      "                               borrow=True,\n",
      "                               # Theano allows for broadcasting, similar to numpy.\n",
      "                               # However, you need to explicitly denote which axes can be broadcasted.\n",
      "                               # By setting broadcastable=(False, True), we are denoting that b\n",
      "                               # can be broadcast (copied) along its second dimension in order to be\n",
      "                               # added to another variable.  For more information, see\n",
      "                               # http://deeplearning.net/software/theano/library/tensor/basic.html\n",
      "                               broadcastable=(False, True))\n",
      "        self.activation = activation\n",
      "        # We'll compute the gradient of the cost of the network with respect to the parameters in this list.\n",
      "        self.params = [self.W, self.b]\n",
      "        \n",
      "    def output(self, x):\n",
      "        '''\n",
      "        Compute this layer's output given an input\n",
      "        \n",
      "        :parameters:\n",
      "            - x : theano.tensor.var.TensorVariable\n",
      "                Theano symbolic variable for layer input\n",
      "\n",
      "        :returns:\n",
      "            - output : theano.tensor.var.TensorVariable\n",
      "                Mixed, biased, and activated x\n",
      "        '''\n",
      "        # Compute linear mix\n",
      "        lin_output = T.dot(self.W, x) + self.b\n",
      "        # Output is just linear mix if no activation function\n",
      "        # Otherwise, apply the activation function\n",
      "        return (lin_output if self.activation is None else self.activation(lin_output))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### MLP class\n",
      "\n",
      "Most of the functionality of our MLP is contained in the `Layer` class; the `MLP` class is essentially just a container for a list of `Layer`s and their parameters.  The `output` function simply recursively computes the output for each layer.  Finally, the `squared_error` returns the squared Euclidean distance between the output of the network given an input and the desired (ground truth) output.  This function is meant to be used as a cost in the setting of minimizing cost over some training data.  As above, the `output` and `squared error` functions are not to be used for actually computing values; instead, they're to be used to create functions which are used to compute values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MLP(object):\n",
      "    def __init__(self, W_init, b_init, activations):\n",
      "        '''\n",
      "        Multi-layer perceptron class, computes the composition of a sequence of Layers\n",
      "\n",
      "        :parameters:\n",
      "            - W_init : list of np.ndarray, len=N\n",
      "                Values to initialize the weight matrix in each layer to.\n",
      "                The layer sizes will be inferred from the shape of each matrix in W_init\n",
      "            - b_init : list of np.ndarray, len=N\n",
      "                Values to initialize the bias vector in each layer to\n",
      "            - activations : list of theano.tensor.elemwise.Elemwise, len=N\n",
      "                Activation function for layer output for each layer\n",
      "        '''\n",
      "        # Make sure the input lists are all of the same length\n",
      "        assert len(W_init) == len(b_init) == len(activations)\n",
      "        \n",
      "        # Initialize lists of layers\n",
      "        self.layers = []\n",
      "        # Construct the layers\n",
      "        for W, b, activation in zip(W_init, b_init, activations):\n",
      "            self.layers.append(Layer(W, b, activation))\n",
      "\n",
      "        # Combine parameters from all layers\n",
      "        self.params = []\n",
      "        for layer in self.layers:\n",
      "            self.params += layer.params\n",
      "        \n",
      "    def output(self, x):\n",
      "        '''\n",
      "        Compute the MLP's output given an input\n",
      "        \n",
      "        :parameters:\n",
      "            - x : theano.tensor.var.TensorVariable\n",
      "                Theano symbolic variable for network input\n",
      "\n",
      "        :returns:\n",
      "            - output : theano.tensor.var.TensorVariable\n",
      "                x passed through the MLP\n",
      "        '''\n",
      "        # Recursively compute output\n",
      "        for layer in self.layers:\n",
      "            x = layer.output(x)\n",
      "        return x\n",
      "\n",
      "    def squared_error(self, x, y):\n",
      "        '''\n",
      "        Compute the squared euclidean error of the network output against the \"true\" output y\n",
      "        \n",
      "        :parameters:\n",
      "            - x : theano.tensor.var.TensorVariable\n",
      "                Theano symbolic variable for network input\n",
      "            - y : theano.tensor.var.TensorVariable\n",
      "                Theano symbolic variable for desired network output\n",
      "\n",
      "        :returns:\n",
      "            - error : theano.tensor.var.TensorVariable\n",
      "                The squared Euclidian distance between the network output and y\n",
      "        '''\n",
      "        return T.sum((self.output(x) - y)**2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Gradient descent\n",
      "\n",
      "To train the network, we will minimize the cost (squared Euclidean distance of network output vs. ground-truth) over a training set using gradient descent.  When doing gradient descent on neural nets, it's very common to use momentum, which is simply a leaky integrator on the parameter update.  That is, when updating parameters, a linear mix of the current gradient update and the previous gradient update is computed.  This tends to make the network converge more quickly on a good solution and can help avoid local minima in the cost function.  With traditional gradient descent, we are guaranteed to decrease the cost at each iteration.  When we use momentum, we lose this guarantee, but this is generally seen as a small price to pay for the improvement momentum usually gives.\n",
      "\n",
      "In Theano, we store the previous parameter update as a shared variable so that its value is preserved across iterations.  Then, during the gradient update, we not only update the parameters, but we also update the previous parameter update shared variable."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gradient_updates_momentum(cost, params, learning_rate, momentum):\n",
      "    '''\n",
      "    Compute updates for gradient descent with momentum\n",
      "    \n",
      "    :parameters:\n",
      "        - cost : theano.tensor.var.TensorVariable\n",
      "            Theano cost function to minimize\n",
      "        - params : list of theano.tensor.var.TensorVariable\n",
      "            Parameters to compute gradient against\n",
      "        - learning_rate : float\n",
      "            Gradient descent learning rate\n",
      "        - momentum : float\n",
      "            Momentum parameter, should at least 0 (standard gradient descent) and less than 1\n",
      "   \n",
      "    :returns:\n",
      "        updates : list\n",
      "            List of updates, one for each parameter\n",
      "    '''\n",
      "    # Make sure momenum is a sane value\n",
      "    assert momentum < 1 and momentum >= 0\n",
      "    # List of update steps for each parameter\n",
      "    updates = []\n",
      "    # Just gradient descent on cost\n",
      "    for param in params:\n",
      "        # For each parameter, we'll create a param_update shared variable.\n",
      "        # This variable will keep track of the parameter's update step across iterations.\n",
      "        # We initialize it to 0\n",
      "        param_update = theano.shared(param.get_value()*0., broadcastable=param.broadcastable)\n",
      "        # Each parameter is updated by taking a step in the direction of the gradient.\n",
      "        # However, we also \"mix in\" the previous step according to the given momentum value.\n",
      "        # Note that when updating param_update, we are using its old value and also the new gradient step.\n",
      "        updates.append((param, param - learning_rate*param_update))\n",
      "        # Note that we don't need to derive backpropagation to compute updates - just use T.grad!\n",
      "        updates.append((param_update, momentum*param_update + (1. - momentum)*T.grad(cost, param)))\n",
      "    return updates"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Toy example\n",
      "\n",
      "We'll train our neural network to classify two Gaussian-distributed clusters in 2d space."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Training data - two randomly-generated Gaussian-distributed clouds of points in 2d space\n",
      "np.random.seed(0)\n",
      "# Number of points\n",
      "N = 1000\n",
      "# Labels for each cluster\n",
      "y = np.random.random_integers(0, 1, N)\n",
      "# Mean of each cluster\n",
      "means = np.array([[-1, 1], [-1, 1]])\n",
      "# Covariance (in X and Y direction) of each cluster\n",
      "covariances = np.random.random_sample((2, 2)) + 1\n",
      "# Dimensions of each point\n",
      "X = np.vstack([np.random.randn(N)*covariances[0, y] + means[0, y],\n",
      "               np.random.randn(N)*covariances[1, y] + means[1, y]])\n",
      "# Plot the data\n",
      "plt.figure(figsize=(8, 8))\n",
      "plt.scatter(X[0, :], X[1, :], c=y, lw=.3, s=3, cmap=plt.cm.cool)\n",
      "plt.axis([-6, 6, -6, 6])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# First, set the size of each layer (and the number of layers)\n",
      "# Input layer size is training data dimensionality (2)\n",
      "# Output size is just 1-d: class label - 0 or 1\n",
      "# Finally, let the hidden layers be twice the size of the input.\n",
      "# If we wanted more layers, we could just add another layer size to this list.\n",
      "layer_sizes = [X.shape[0], X.shape[0]*2, 1]\n",
      "# Set initial parameter values\n",
      "W_init = []\n",
      "b_init = []\n",
      "activations = []\n",
      "for n_input, n_output in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
      "    # Getting the correct initialization matters a lot for non-toy problems.\n",
      "    # However, here we can just use the following initialization with success:\n",
      "    # Normally distribute initial weights\n",
      "    W_init.append(np.random.randn(n_output, n_input))\n",
      "    # Set initial biases to 1\n",
      "    b_init.append(np.ones(n_output))\n",
      "    # We'll use sigmoid activation for all layers\n",
      "    # Note that this doesn't make a ton of sense when using squared distance\n",
      "    # because the sigmoid function is bounded on [0, 1].\n",
      "    activations.append(T.nnet.sigmoid)\n",
      "# Create an instance of the MLP class\n",
      "mlp = MLP(W_init, b_init, activations)\n",
      "\n",
      "# Create Theano variables for the MLP input\n",
      "mlp_input = T.matrix('mlp_input')\n",
      "# ... and the desired output\n",
      "mlp_target = T.vector('mlp_target')\n",
      "# Learning rate and momentum hyperparameter values\n",
      "# Again, for non-toy problems these values can make a big difference\n",
      "# as to whether the network (quickly) converges on a good local minimum.\n",
      "learning_rate = 0.01\n",
      "momentum = 0.9\n",
      "# Create a function for computing the cost of the network given an input\n",
      "cost = mlp.squared_error(mlp_input, mlp_target)\n",
      "# Create a theano function for training the network\n",
      "train = theano.function([mlp_input, mlp_target], cost,\n",
      "                        updates=gradient_updates_momentum(cost, mlp.params, learning_rate, momentum))\n",
      "# Create a theano function for computing the MLP's output given some input\n",
      "mlp_output = theano.function([mlp_input], mlp.output(mlp_input))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Keep track of the number of training iterations performed\n",
      "iteration = 0\n",
      "# We'll only train the network with 20 iterations.\n",
      "# A more common technique is to use a hold-out validation set.\n",
      "# When the validation error starts to increase, the network is overfitting,\n",
      "# so we stop training the net.  This is called \"early stopping\", which we won't do here.\n",
      "max_iteration = 20\n",
      "while iteration < max_iteration:\n",
      "    # Train the network using the entire training set.\n",
      "    # With large datasets, it's much more common to use stochastic or mini-batch gradient descent\n",
      "    # where only a subset (or a single point) of the training set is used at each iteration.\n",
      "    # This can also help the network to avoid local minima.\n",
      "    current_cost = train(X, y)\n",
      "    # Get the current network output for all points in the training set\n",
      "    current_output = mlp_output(X)\n",
      "    # We can compute the accuracy by thresholding the output\n",
      "    # and computing the proportion of points whose class match the ground truth class.\n",
      "    accuracy = np.mean((current_output > .5) == y)\n",
      "    # Plot network output after this iteration\n",
      "    plt.figure(figsize=(8, 8))\n",
      "    plt.scatter(X[0, :], X[1, :], c=current_output,\n",
      "                lw=.3, s=3, cmap=plt.cm.cool, vmin=0, vmax=1)\n",
      "    plt.axis([-6, 6, -6, 6])\n",
      "    plt.title('Cost: {:.3f}, Accuracy: {:.3f}'.format(float(current_cost), accuracy))\n",
      "    plt.show()\n",
      "    iteration += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "align_type": "Left",
       "slide_type": "fragment"
      }
     },
     "source": [
      "# References\n",
      "Some useful notebooks adapted here:\n",
      "\n",
      "* [Theano project tutorial](http://nbviewer.ipython.org/github/craffel/theano-tutorial/blob/master/Theano%20Tutorial.ipynb)\n",
      "* [Alexander Fabisch's ML tutorial](http://nbviewer.ipython.org/github/AlexanderFabisch/ml_tutorials/blob/gh-pages/03_ann.ipynb)\n",
      "- [Aaron Masino's ANN notebook](http://nbviewer.ipython.org/github/masinoa/machine_learning/blob/master/04_Neural_Networks.ipynb)\n",
      "\n",
      "See also the following ANN and supporting code implementations:\n",
      "* [Deeplearning4j](http://deeplearning4j.org/) deep-learning library written in Java.\n",
      "* [Neural Network Package](http://torch.cogbits.com/doc/nn/index.html) in LuaJIT (based on [Torch 7](http://torch.cogbits.com/doc/index.html))\n",
      "* [Pylearn 2](http://deeplearning.net/software/pylearn2/) in Python (based on [Theano](http://deeplearning.net/software/theano/))\n",
      "* [cuda-convnet](http://code.google.com/p/cuda-convnet/) in CUDA/Python\n",
      "* [OpenANN](https://github.com/OpenANN/OpenANN) in C++/Python (based on [Eigen](http://eigen.tuxfamily.org/index.php?title=Main_Page))\n",
      "\n",
      "For more tips on ANN tips see:\n",
      "* [Neural Networks: Tricks of the Trade](http://link.springer.com/book/10.1007%2F978-3-642-35289-8) (2nd edition: 2012)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}